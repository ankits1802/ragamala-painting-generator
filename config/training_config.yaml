# =============================================================================
# RAGAMALA PAINTING GENERATOR - TRAINING CONFIGURATION
# =============================================================================
# Comprehensive training hyperparameters for SDXL 1.0 fine-tuning
# Optimized for Ragamala painting generation on EC2 instances

# =============================================================================
# BASIC TRAINING PARAMETERS
# =============================================================================
training:
  # Learning parameters
  learning_rate: 1.0e-4
  lr_scheduler: "cosine"
  lr_warmup_steps: 500
  lr_num_cycles: 1
  lr_power: 1.0
  
  # Batch and gradient settings
  train_batch_size: 4
  gradient_accumulation_steps: 4
  gradient_checkpointing: true
  max_grad_norm: 1.0
  
  # Training duration
  max_train_steps: 10000
  num_train_epochs: 2
  max_train_samples: null
  
  # Validation and checkpointing
  validation_steps: 500
  validation_epochs: 1
  checkpointing_steps: 1000
  save_steps: 1000
  save_total_limit: 5
  
  # Resume training
  resume_from_checkpoint: null
  allow_tf32: true
  
  # Mixed precision and optimization
  mixed_precision: "fp16"
  use_8bit_adam: false
  enable_xformers_memory_efficient_attention: true
  
  # Random seed
  seed: 42
  
  # Data loading
  dataloader_num_workers: 4
  pin_memory: true
  persistent_workers: true

# =============================================================================
# OPTIMIZER CONFIGURATION
# =============================================================================
optimizer:
  type: "AdamW"
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_weight_decay: 1.0e-2
  adam_epsilon: 1.0e-8
  
  # Alternative optimizers
  use_lion: false
  lion_beta1: 0.95
  lion_beta2: 0.98
  lion_weight_decay: 1.0e-2

# =============================================================================
# LORA CONFIGURATION
# =============================================================================
lora:
  # LoRA parameters
  rank: 64
  alpha: 32
  dropout: 0.1
  bias: "none"
  
  # Target modules for SDXL
  target_modules:
    - "to_k"
    - "to_q"
    - "to_v"
    - "to_out.0"
    - "ff.net.0.proj"
    - "ff.net.2"
  
  # LoRA scaling
  lora_scale: 1.0
  init_lora_weights: true
  
  # Text encoder LoRA
  train_text_encoder: false
  text_encoder_lr: 5.0e-5
  text_encoder_rank: 4
  text_encoder_alpha: 16

# =============================================================================
# DATA CONFIGURATION
# =============================================================================
data:
  # Dataset paths
  train_data_dir: "data/processed/train"
  validation_data_dir: "data/processed/validation"
  instance_data_dir: "data/processed/instance"
  class_data_dir: "data/processed/class"
  
  # Image preprocessing
  resolution: 1024
  center_crop: true
  random_flip: true
  color_jitter: false
  
  # Data augmentation
  enable_augmentation: true
  augmentation_strength: 0.3
  
  # Caption and prompt settings
  instance_prompt: "a ragamala painting"
  class_prompt: "a traditional indian painting"
  caption_column: "text"
  image_column: "image"
  
  # Prior preservation
  with_prior_preservation: true
  prior_loss_weight: 1.0
  num_class_images: 100
  sample_batch_size: 4

# =============================================================================
# MODEL CONFIGURATION
# =============================================================================
model:
  # Base model
  pretrained_model_name_or_path: "stabilityai/stable-diffusion-xl-base-1.0"
  pretrained_vae_model_name_or_path: "madebyollin/sdxl-vae-fp16-fix"
  revision: null
  variant: null
  
  # Model components
  train_unet: true
  train_text_encoder: false
  train_text_encoder_2: false
  
  # Noise scheduler
  noise_scheduler: "DDPMScheduler"
  prediction_type: "epsilon"
  
  # VAE settings
  enable_vae_slicing: true
  enable_vae_tiling: false
  
  # Memory optimization
  enable_cpu_offload: false
  enable_model_cpu_offload: false
  enable_attention_slicing: true

# =============================================================================
# CULTURAL SPECIFIC CONFIGURATION
# =============================================================================
cultural:
  # Raga-specific training
  enable_raga_conditioning: true
  raga_weight: 0.1
  supported_ragas:
    - "bhairav"
    - "malkauns"
    - "yaman"
    - "bhimpalasi"
    - "darbari"
    - "marwa"
    - "puriya"
    - "todi"
    - "bageshri"
    - "kafi"
  
  # Style-specific training
  enable_style_conditioning: true
  style_weight: 0.05
  supported_styles:
    - "rajput"
    - "pahari"
    - "deccan"
    - "mughal"
    - "kangra"
    - "basohli"
    - "mewar"
    - "bundi"
  
  # Cultural consistency
  cultural_consistency_weight: 0.05
  preserve_iconography: true
  maintain_color_palette: true

# =============================================================================
# LOSS CONFIGURATION
# =============================================================================
loss:
  # Primary loss
  main_loss_type: "mse"
  
  # Additional losses
  enable_perceptual_loss: false
  perceptual_loss_weight: 0.1
  
  enable_style_loss: true
  style_loss_weight: 0.05
  
  enable_cultural_loss: true
  cultural_loss_weight: 0.1
  
  # SNR weighting
  snr_gamma: 5.0
  enable_snr_weighting: false

# =============================================================================
# VALIDATION CONFIGURATION
# =============================================================================
validation:
  # Validation prompts
  validation_prompts:
    - "A rajput style ragamala painting depicting raga bhairav at dawn"
    - "A pahari miniature showing raga yaman in moonlight"
    - "A deccan painting of raga malkauns with deep blues and purples"
    - "A mughal style artwork representing raga darbari with royal themes"
    - "A kangra painting of raga bageshri with romantic motifs"
  
  # Validation settings
  num_validation_images: 4
  validation_scheduler: "DPMSolverMultistepScheduler"
  validation_guidance_scale: 7.5
  validation_num_inference_steps: 30
  
  # Validation frequency
  run_validation: true
  validation_epochs: 1

# =============================================================================
# LOGGING AND MONITORING
# =============================================================================
logging:
  # Output directories
  output_dir: "outputs/training"
  logging_dir: "logs/training"
  
  # Logging frequency
  log_every_n_steps: 10
  save_images_every_n_steps: 500
  
  # Weights & Biases
  enable_wandb: true
  wandb_project: "ragamala-sdxl"
  wandb_entity: null
  wandb_run_name: null
  
  # TensorBoard
  enable_tensorboard: true
  tensorboard_log_dir: "logs/tensorboard"
  
  # MLflow
  enable_mlflow: false
  mlflow_tracking_uri: "http://localhost:5000"
  mlflow_experiment_name: "ragamala-experiments"

# =============================================================================
# HARDWARE CONFIGURATION
# =============================================================================
hardware:
  # GPU settings
  use_gpu: true
  gpu_ids: [0]
  mixed_precision_policy: "fp16"
  
  # Memory management
  gradient_checkpointing: true
  max_memory_usage: "16GB"
  
  # Distributed training
  enable_distributed: false
  world_size: 1
  rank: 0
  local_rank: 0
  
  # Performance optimization
  compile_model: false
  use_torch_compile: false

# =============================================================================
# EVALUATION CONFIGURATION
# =============================================================================
evaluation:
  # Metrics
  compute_fid: true
  compute_clip_score: true
  compute_lpips: true
  compute_ssim: true
  
  # Cultural evaluation
  enable_cultural_evaluation: true
  cultural_expert_validation: false
  
  # Human evaluation
  enable_human_evaluation: false
  human_eval_samples: 50

# =============================================================================
# EXPERIMENTAL FEATURES
# =============================================================================
experimental:
  # Advanced techniques
  enable_dreambooth: false
  enable_textual_inversion: false
  enable_controlnet: false
  
  # Multi-aspect training
  enable_multi_aspect_ratio: false
  aspect_ratios:
    - [1024, 1024]
    - [1152, 896]
    - [896, 1152]
    - [1216, 832]
    - [832, 1216]
  
  # Advanced data augmentation
  enable_advanced_augmentation: false
  mixup_alpha: 0.2
  cutmix_alpha: 1.0

# =============================================================================
# SAFETY AND COMPLIANCE
# =============================================================================
safety:
  # Content filtering
  enable_safety_checker: false
  nsfw_filter_strength: 0.5
  
  # Cultural sensitivity
  respect_cultural_context: true
  avoid_stereotypes: true
  maintain_authenticity: true

# =============================================================================
# DEPLOYMENT PREPARATION
# =============================================================================
deployment:
  # Model export
  export_format: "safetensors"
  quantization: null
  
  # Optimization
  optimize_for_inference: true
  enable_torch_script: false
  
  # Packaging
  include_metadata: true
  include_training_config: true