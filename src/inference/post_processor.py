"""
Post-Processing Module for Ragamala Painting Generation.

This module provides comprehensive post-processing functionality for refining
generated Ragamala paintings, including quality enhancement, cultural validation,
style transfer, and artistic refinement techniques.
"""

import os
import sys
import time
import json
import logging
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Union, Any, Callable
from dataclasses import dataclass, asdict
import numpy as np
from PIL import Image, ImageEnhance, ImageFilter, ImageOps, ImageDraw, ImageFont
import cv2
import torch
import torch.nn.functional as F
from torchvision import transforms
import warnings
warnings.filterwarnings("ignore")

# Diffusers imports
from diffusers import (
    StableDiffusionXLImg2ImgPipeline,
    StableDiffusionXLInpaintPipeline,
    AutoPipelineForImage2Image
)

# Computer vision imports
from skimage import exposure, filters, morphology, segmentation
from skimage.feature import local_binary_pattern
from skimage.color import rgb2hsv, hsv2rgb, rgb2lab, lab2rgb
from scipy import ndimage
from scipy.ndimage import gaussian_filter

# CLIP imports
from transformers import CLIPProcessor, CLIPModel

# Super-resolution imports
try:
    from realesrgan import RealESRGANer
    from basicsr.archs.rrdbnet_arch import RRDBNet
    REALESRGAN_AVAILABLE = True
except ImportError:
    REALESRGAN_AVAILABLE = False
    logging.warning("RealESRGAN not available. Install with: pip install realesrgan")

# Add project root to path
sys.path.append(str(Path(__file__).parent.parent.parent))

from src.utils.logging_utils import setup_logger

logger = setup_logger(__name__)

@dataclass
class PostProcessingConfig:
    """Configuration for post-processing operations."""
    # Enhancement settings
    enable_super_resolution: bool = True
    super_resolution_scale: int = 2
    super_resolution_model: str = "RealESRGAN_x2plus"
    
    # Color correction
    enable_color_correction: bool = True
    gamma_correction: float = 1.0
    brightness_adjustment: float = 0.0
    contrast_adjustment: float = 1.0
    saturation_adjustment: float = 1.0
    
    # Noise reduction
    enable_denoising: bool = True
    denoise_strength: float = 0.3
    preserve_details: bool = True
    
    # Sharpening
    enable_sharpening: bool = True
    sharpening_strength: float = 0.5
    unsharp_mask_radius: float = 1.0
    unsharp_mask_amount: float = 1.5
    
    # Cultural refinement
    enable_cultural_refinement: bool = True
    cultural_style_strength: float = 0.3
    preserve_iconography: bool = True
    
    # Artistic enhancement
    enable_artistic_enhancement: bool = True
    texture_enhancement: bool = True
    edge_enhancement: bool = True
    
    # Watermarking
    enable_watermarking: bool = False
    watermark_text: str = "Generated by Ragamala AI"
    watermark_opacity: float = 0.1
    
    # Output settings
    output_format: str = "PNG"
    output_quality: int = 95
    preserve_metadata: bool = True

@dataclass
class ProcessingResult:
    """Result of post-processing operations."""
    processed_image: Image.Image
    original_image: Image.Image
    processing_time: float
    operations_applied: List[str]
    quality_metrics: Dict[str, float]
    metadata: Dict[str, Any]

class SuperResolutionProcessor:
    """Super-resolution processor using RealESRGAN."""
    
    def __init__(self, model_name: str = "RealESRGAN_x2plus", scale: int = 2):
        self.model_name = model_name
        self.scale = scale
        self.upsampler = None
        
        if REALESRGAN_AVAILABLE:
            self._initialize_model()
    
    def _initialize_model(self):
        """Initialize RealESRGAN model."""
        try:
            # Model configurations
            model_configs = {
                "RealESRGAN_x2plus": {
                    "model_path": "weights/RealESRGAN_x2plus.pth",
                    "netscale": 2,
                    "model": RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=2)
                },
                "RealESRGAN_x4plus": {
                    "model_path": "weights/RealESRGAN_x4plus.pth", 
                    "netscale": 4,
                    "model": RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=4)
                }
            }
            
            config = model_configs.get(self.model_name, model_configs["RealESRGAN_x2plus"])
            
            self.upsampler = RealESRGANer(
                scale=config["netscale"],
                model_path=config["model_path"],
                model=config["model"],
                tile=400,
                tile_pad=10,
                pre_pad=0,
                half=True
            )
            
            logger.info(f"RealESRGAN {self.model_name} initialized")
            
        except Exception as e:
            logger.error(f"Failed to initialize RealESRGAN: {e}")
            self.upsampler = None
    
    def enhance(self, image: Image.Image) -> Image.Image:
        """Enhance image using super-resolution."""
        if not REALESRGAN_AVAILABLE or self.upsampler is None:
            # Fallback to bicubic upsampling
            return self._bicubic_upscale(image)
        
        try:
            # Convert PIL to numpy
            img_array = np.array(image)
            
            # Apply super-resolution
            output, _ = self.upsampler.enhance(img_array, outscale=self.scale)
            
            # Convert back to PIL
            enhanced_image = Image.fromarray(output)
            
            return enhanced_image
            
        except Exception as e:
            logger.error(f"Super-resolution failed: {e}")
            return self._bicubic_upscale(image)
    
    def _bicubic_upscale(self, image: Image.Image) -> Image.Image:
        """Fallback bicubic upscaling."""
        new_size = (image.width * self.scale, image.height * self.scale)
        return image.resize(new_size, Image.BICUBIC)

class ColorCorrector:
    """Color correction and enhancement processor."""
    
    def __init__(self):
        self.cultural_color_profiles = self._load_cultural_color_profiles()
    
    def _load_cultural_color_profiles(self) -> Dict[str, Dict[str, Any]]:
        """Load cultural color profiles for different styles."""
        return {
            'rajput': {
                'gamma': 0.95,
                'saturation_boost': 1.15,
                'red_enhancement': 1.1,
                'gold_enhancement': 1.2,
                'contrast_boost': 1.05
            },
            'pahari': {
                'gamma': 1.05,
                'saturation_boost': 1.05,
                'blue_enhancement': 1.1,
                'green_enhancement': 1.1,
                'contrast_boost': 1.02
            },
            'deccan': {
                'gamma': 0.9,
                'saturation_boost': 1.2,
                'blue_enhancement': 1.15,
                'purple_enhancement': 1.1,
                'contrast_boost': 1.1
            },
            'mughal': {
                'gamma': 1.0,
                'saturation_boost': 1.1,
                'gold_enhancement': 1.15,
                'overall_richness': 1.05,
                'contrast_boost': 1.08
            }
        }
    
    def correct_colors(self, 
                      image: Image.Image,
                      style: Optional[str] = None,
                      gamma: float = 1.0,
                      brightness: float = 0.0,
                      contrast: float = 1.0,
                      saturation: float = 1.0) -> Image.Image:
        """Apply color correction to image."""
        corrected = image.copy()
        
        # Apply style-specific corrections
        if style and style in self.cultural_color_profiles:
            profile = self.cultural_color_profiles[style]
            gamma = gamma * profile.get('gamma', 1.0)
            saturation = saturation * profile.get('saturation_boost', 1.0)
            contrast = contrast * profile.get('contrast_boost', 1.0)
        
        # Gamma correction
        if gamma != 1.0:
            corrected = self._apply_gamma_correction(corrected, gamma)
        
        # Brightness adjustment
        if brightness != 0.0:
            enhancer = ImageEnhance.Brightness(corrected)
            corrected = enhancer.enhance(1.0 + brightness)
        
        # Contrast adjustment
        if contrast != 1.0:
            enhancer = ImageEnhance.Contrast(corrected)
            corrected = enhancer.enhance(contrast)
        
        # Saturation adjustment
        if saturation != 1.0:
            enhancer = ImageEnhance.Color(corrected)
            corrected = enhancer.enhance(saturation)
        
        # Style-specific enhancements
        if style and style in self.cultural_color_profiles:
            corrected = self._apply_style_specific_enhancement(corrected, style)
        
        return corrected
    
    def _apply_gamma_correction(self, image: Image.Image, gamma: float) -> Image.Image:
        """Apply gamma correction."""
        # Convert to numpy array
        img_array = np.array(image).astype(np.float32) / 255.0
        
        # Apply gamma correction
        corrected_array = np.power(img_array, 1.0 / gamma)
        
        # Convert back to PIL
        corrected_array = (corrected_array * 255).astype(np.uint8)
        return Image.fromarray(corrected_array)
    
    def _apply_style_specific_enhancement(self, image: Image.Image, style: str) -> Image.Image:
        """Apply style-specific color enhancements."""
        profile = self.cultural_color_profiles[style]
        
        # Convert to HSV for selective color enhancement
        hsv_array = np.array(image.convert('HSV'))
        h, s, v = hsv_array[:, :, 0], hsv_array[:, :, 1], hsv_array[:, :, 2]
        
        if style == 'rajput':
            # Enhance reds (hue 0-20 and 340-360)
            red_mask = (h <= 20) | (h >= 340)
            s[red_mask] = np.clip(s[red_mask] * profile.get('red_enhancement', 1.0), 0, 255)
            
            # Enhance golds/yellows (hue 40-70)
            gold_mask = (h >= 40) & (h <= 70)
            s[gold_mask] = np.clip(s[gold_mask] * profile.get('gold_enhancement', 1.0), 0, 255)
            
        elif style == 'pahari':
            # Enhance blues (hue 200-260)
            blue_mask = (h >= 200) & (h <= 260)
            s[blue_mask] = np.clip(s[blue_mask] * profile.get('blue_enhancement', 1.0), 0, 255)
            
            # Enhance greens (hue 80-140)
            green_mask = (h >= 80) & (h <= 140)
            s[green_mask] = np.clip(s[green_mask] * profile.get('green_enhancement', 1.0), 0, 255)
        
        # Reconstruct image
        enhanced_hsv = np.stack([h, s, v], axis=2).astype(np.uint8)
        enhanced_image = Image.fromarray(enhanced_hsv, mode='HSV').convert('RGB')
        
        return enhanced_image

class NoiseReducer:
    """Noise reduction processor."""
    
    def __init__(self):
        pass
    
    def reduce_noise(self, 
                    image: Image.Image,
                    strength: float = 0.3,
                    preserve_details: bool = True) -> Image.Image:
        """Reduce noise while preserving details."""
        # Convert to numpy array
        img_array = np.array(image)
        
        if preserve_details:
            # Use edge-preserving filter
            denoised = self._bilateral_filter(img_array, strength)
        else:
            # Use Gaussian filter
            denoised = self._gaussian_filter(img_array, strength)
        
        return Image.fromarray(denoised)
    
    def _bilateral_filter(self, img_array: np.ndarray, strength: float) -> np.ndarray:
        """Apply bilateral filter for edge-preserving denoising."""
        # Convert strength to bilateral filter parameters
        d = int(9 * strength)
        sigma_color = 75 * strength
        sigma_space = 75 * strength
        
        # Apply bilateral filter
        denoised = cv2.bilateralFilter(img_array, d, sigma_color, sigma_space)
        
        return denoised
    
    def _gaussian_filter(self, img_array: np.ndarray, strength: float) -> np.ndarray:
        """Apply Gaussian filter for noise reduction."""
        sigma = 2.0 * strength
        
        # Apply Gaussian filter to each channel
        denoised = np.zeros_like(img_array)
        for i in range(img_array.shape[2]):
            denoised[:, :, i] = gaussian_filter(img_array[:, :, i], sigma=sigma)
        
        return denoised.astype(np.uint8)

class ImageSharpener:
    """Image sharpening processor."""
    
    def __init__(self):
        pass
    
    def sharpen_image(self, 
                     image: Image.Image,
                     strength: float = 0.5,
                     radius: float = 1.0,
                     amount: float = 1.5) -> Image.Image:
        """Apply unsharp mask sharpening."""
        # Convert to numpy array
        img_array = np.array(image).astype(np.float32)
        
        # Create Gaussian blur
        blurred = gaussian_filter(img_array, sigma=radius)
        
        # Create unsharp mask
        unsharp_mask = img_array - blurred
        
        # Apply sharpening
        sharpened = img_array + (amount * strength) * unsharp_mask
        
        # Clip values and convert back
        sharpened = np.clip(sharpened, 0, 255).astype(np.uint8)
        
        return Image.fromarray(sharpened)

class CulturalRefinementProcessor:
    """Processor for cultural refinement using SDXL."""
    
    def __init__(self, model_path: str = "stabilityai/stable-diffusion-xl-refiner-1.0"):
        self.model_path = model_path
        self.pipeline = None
        self._load_pipeline()
    
    def _load_pipeline(self):
        """Load SDXL refiner pipeline."""
        try:
            self.pipeline = StableDiffusionXLImg2ImgPipeline.from_pretrained(
                self.model_path,
                torch_dtype=torch.float16,
                variant="fp16",
                use_safetensors=True
            )
            
            if torch.cuda.is_available():
                self.pipeline.to("cuda")
            
            # Enable optimizations
            self.pipeline.enable_xformers_memory_efficient_attention()
            self.pipeline.enable_vae_slicing()
            
            logger.info("Cultural refinement pipeline loaded")
            
        except Exception as e:
            logger.error(f"Failed to load refinement pipeline: {e}")
            self.pipeline = None
    
    def refine_cultural_style(self, 
                            image: Image.Image,
                            style: str,
                            raga: str,
                            strength: float = 0.3) -> Image.Image:
        """Refine image to enhance cultural style."""
        if self.pipeline is None:
            logger.warning("Refinement pipeline not available")
            return image
        
        try:
            # Create style-specific prompt
            style_prompt = self._create_style_prompt(style, raga)
            
            # Apply refinement
            refined_image = self.pipeline(
                prompt=style_prompt,
                image=image,
                strength=strength,
                num_inference_steps=20,
                guidance_scale=7.5
            ).images[0]
            
            return refined_image
            
        except Exception as e:
            logger.error(f"Cultural refinement failed: {e}")
            return image
    
    def _create_style_prompt(self, style: str, raga: str) -> str:
        """Create style-specific prompt for refinement."""
        style_prompts = {
            'rajput': f"authentic rajput style ragamala painting of raga {raga}, bold colors, geometric patterns, traditional indian art",
            'pahari': f"delicate pahari miniature of raga {raga}, soft colors, natural settings, himalayan art style",
            'deccan': f"deccan school painting of raga {raga}, persian influence, architectural elements, rich colors",
            'mughal': f"mughal court painting of raga {raga}, elaborate details, fine miniature work, imperial style"
        }
        
        return style_prompts.get(style, f"traditional indian ragamala painting of raga {raga}")

class ArtisticEnhancer:
    """Artistic enhancement processor."""
    
    def __init__(self):
        pass
    
    def enhance_texture(self, image: Image.Image, strength: float = 0.5) -> Image.Image:
        """Enhance texture details in the image."""
        # Convert to numpy array
        img_array = np.array(image)
        
        # Apply local binary pattern for texture enhancement
        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
        
        # Calculate LBP
        radius = 3
        n_points = 8 * radius
        lbp = local_binary_pattern(gray, n_points, radius, method='uniform')
        
        # Normalize LBP
        lbp_normalized = (lbp / lbp.max() * 255).astype(np.uint8)
        
        # Create texture mask
        texture_mask = cv2.GaussianBlur(lbp_normalized, (5, 5), 0)
        texture_mask = texture_mask / 255.0
        
        # Apply texture enhancement
        enhanced = img_array.copy().astype(np.float32)
        for i in range(3):  # RGB channels
            enhanced[:, :, i] = enhanced[:, :, i] * (1 + strength * texture_mask)
        
        enhanced = np.clip(enhanced, 0, 255).astype(np.uint8)
        
        return Image.fromarray(enhanced)
    
    def enhance_edges(self, image: Image.Image, strength: float = 0.3) -> Image.Image:
        """Enhance edges in the image."""
        # Convert to numpy array
        img_array = np.array(image)
        
        # Convert to grayscale for edge detection
        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
        
        # Apply Canny edge detection
        edges = cv2.Canny(gray, 50, 150)
        
        # Dilate edges slightly
        kernel = np.ones((3, 3), np.uint8)
        edges = cv2.dilate(edges, kernel, iterations=1)
        
        # Create edge mask
        edge_mask = edges / 255.0
        
        # Apply edge enhancement
        enhanced = img_array.copy().astype(np.float32)
        for i in range(3):  # RGB channels
            enhanced[:, :, i] = enhanced[:, :, i] * (1 + strength * edge_mask)
        
        enhanced = np.clip(enhanced, 0, 255).astype(np.uint8)
        
        return Image.fromarray(enhanced)

class WatermarkProcessor:
    """Watermark processor for generated images."""
    
    def __init__(self):
        pass
    
    def add_watermark(self, 
                     image: Image.Image,
                     text: str = "Generated by Ragamala AI",
                     opacity: float = 0.1,
                     position: str = "bottom_right") -> Image.Image:
        """Add watermark to image."""
        # Create a copy of the image
        watermarked = image.copy()
        
        # Create watermark overlay
        overlay = Image.new('RGBA', image.size, (255, 255, 255, 0))
        draw = ImageDraw.Draw(overlay)
        
        # Try to load a font
        try:
            font_size = max(12, min(image.width, image.height) // 50)
            font = ImageFont.truetype("arial.ttf", font_size)
        except:
            font = ImageFont.load_default()
        
        # Get text size
        bbox = draw.textbbox((0, 0), text, font=font)
        text_width = bbox[2] - bbox[0]
        text_height = bbox[3] - bbox[1]
        
        # Calculate position
        margin = 10
        if position == "bottom_right":
            x = image.width - text_width - margin
            y = image.height - text_height - margin
        elif position == "bottom_left":
            x = margin
            y = image.height - text_height - margin
        elif position == "top_right":
            x = image.width - text_width - margin
            y = margin
        else:  # top_left
            x = margin
            y = margin
        
        # Draw watermark
        alpha = int(255 * opacity)
        draw.text((x, y), text, font=font, fill=(255, 255, 255, alpha))
        
        # Composite watermark
        watermarked = Image.alpha_composite(watermarked.convert('RGBA'), overlay)
        
        return watermarked.convert('RGB')

class QualityMetricsCalculator:
    """Calculate quality metrics for processed images."""
    
    def __init__(self):
        pass
    
    def calculate_metrics(self, 
                         original: Image.Image,
                         processed: Image.Image) -> Dict[str, float]:
        """Calculate quality metrics comparing original and processed images."""
        # Convert to numpy arrays
        orig_array = np.array(original)
        proc_array = np.array(processed)
        
        # Ensure same size
        if orig_array.shape != proc_array.shape:
            processed_resized = processed.resize(original.size, Image.LANCZOS)
            proc_array = np.array(processed_resized)
        
        metrics = {}
        
        # PSNR (Peak Signal-to-Noise Ratio)
        metrics['psnr'] = self._calculate_psnr(orig_array, proc_array)
        
        # SSIM (Structural Similarity Index)
        metrics['ssim'] = self._calculate_ssim(orig_array, proc_array)
        
        # Mean Squared Error
        metrics['mse'] = self._calculate_mse(orig_array, proc_array)
        
        # Sharpness measure
        metrics['sharpness'] = self._calculate_sharpness(proc_array)
        
        # Contrast measure
        metrics['contrast'] = self._calculate_contrast(proc_array)
        
        # Color richness
        metrics['color_richness'] = self._calculate_color_richness(proc_array)
        
        return metrics
    
    def _calculate_psnr(self, img1: np.ndarray, img2: np.ndarray) -> float:
        """Calculate PSNR between two images."""
        mse = np.mean((img1 - img2) ** 2)
        if mse == 0:
            return float('inf')
        
        max_pixel = 255.0
        psnr = 20 * np.log10(max_pixel / np.sqrt(mse))
        return float(psnr)
    
    def _calculate_ssim(self, img1: np.ndarray, img2: np.ndarray) -> float:
        """Calculate SSIM between two images."""
        # Convert to grayscale
        gray1 = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)
        gray2 = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)
        
        # Calculate means
        mu1 = gray1.mean()
        mu2 = gray2.mean()
        
        # Calculate variances and covariance
        var1 = gray1.var()
        var2 = gray2.var()
        cov = np.mean((gray1 - mu1) * (gray2 - mu2))
        
        # SSIM constants
        c1 = (0.01 * 255) ** 2
        c2 = (0.03 * 255) ** 2
        
        # Calculate SSIM
        ssim = ((2 * mu1 * mu2 + c1) * (2 * cov + c2)) / ((mu1**2 + mu2**2 + c1) * (var1 + var2 + c2))
        
        return float(ssim)
    
    def _calculate_mse(self, img1: np.ndarray, img2: np.ndarray) -> float:
        """Calculate Mean Squared Error."""
        return float(np.mean((img1 - img2) ** 2))
    
    def _calculate_sharpness(self, img: np.ndarray) -> float:
        """Calculate image sharpness using Laplacian variance."""
        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
        laplacian = cv2.Laplacian(gray, cv2.CV_64F)
        return float(laplacian.var())
    
    def _calculate_contrast(self, img: np.ndarray) -> float:
        """Calculate image contrast using RMS contrast."""
        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
        return float(gray.std())
    
    def _calculate_color_richness(self, img: np.ndarray) -> float:
        """Calculate color richness as variance in color channels."""
        color_vars = [img[:, :, i].var() for i in range(3)]
        return float(np.mean(color_vars))

class RagamalaPostProcessor:
    """Main post-processor for Ragamala paintings."""
    
    def __init__(self, config: PostProcessingConfig):
        self.config = config
        
        # Initialize processors
        self.super_resolution = SuperResolutionProcessor(
            model_name=config.super_resolution_model,
            scale=config.super_resolution_scale
        ) if config.enable_super_resolution else None
        
        self.color_corrector = ColorCorrector()
        self.noise_reducer = NoiseReducer()
        self.sharpener = ImageSharpener()
        
        self.cultural_refiner = CulturalRefinementProcessor() if config.enable_cultural_refinement else None
        self.artistic_enhancer = ArtisticEnhancer()
        self.watermark_processor = WatermarkProcessor()
        self.quality_calculator = QualityMetricsCalculator()
    
    def process_image(self, 
                     image: Image.Image,
                     style: Optional[str] = None,
                     raga: Optional[str] = None,
                     metadata: Optional[Dict[str, Any]] = None) -> ProcessingResult:
        """Process image with all enabled enhancements."""
        start_time = time.time()
        original_image = image.copy()
        processed_image = image.copy()
        operations_applied = []
        
        try:
            # Super-resolution
            if self.config.enable_super_resolution and self.super_resolution:
                processed_image = self.super_resolution.enhance(processed_image)
                operations_applied.append("super_resolution")
                logger.info("Applied super-resolution")
            
            # Color correction
            if self.config.enable_color_correction:
                processed_image = self.color_corrector.correct_colors(
                    processed_image,
                    style=style,
                    gamma=self.config.gamma_correction,
                    brightness=self.config.brightness_adjustment,
                    contrast=self.config.contrast_adjustment,
                    saturation=self.config.saturation_adjustment
                )
                operations_applied.append("color_correction")
                logger.info("Applied color correction")
            
            # Noise reduction
            if self.config.enable_denoising:
                processed_image = self.noise_reducer.reduce_noise(
                    processed_image,
                    strength=self.config.denoise_strength,
                    preserve_details=self.config.preserve_details
                )
                operations_applied.append("noise_reduction")
                logger.info("Applied noise reduction")
            
            # Sharpening
            if self.config.enable_sharpening:
                processed_image = self.sharpener.sharpen_image(
                    processed_image,
                    strength=self.config.sharpening_strength,
                    radius=self.config.unsharp_mask_radius,
                    amount=self.config.unsharp_mask_amount
                )
                operations_applied.append("sharpening")
                logger.info("Applied sharpening")
            
            # Cultural refinement
            if (self.config.enable_cultural_refinement and 
                self.cultural_refiner and style and raga):
                processed_image = self.cultural_refiner.refine_cultural_style(
                    processed_image,
                    style=style,
                    raga=raga,
                    strength=self.config.cultural_style_strength
                )
                operations_applied.append("cultural_refinement")
                logger.info("Applied cultural refinement")
            
            # Artistic enhancement
            if self.config.enable_artistic_enhancement:
                if self.config.texture_enhancement:
                    processed_image = self.artistic_enhancer.enhance_texture(processed_image)
                    operations_applied.append("texture_enhancement")
                
                if self.config.edge_enhancement:
                    processed_image = self.artistic_enhancer.enhance_edges(processed_image)
                    operations_applied.append("edge_enhancement")
                
                logger.info("Applied artistic enhancement")
            
            # Watermarking
            if self.config.enable_watermarking:
                processed_image = self.watermark_processor.add_watermark(
                    processed_image,
                    text=self.config.watermark_text,
                    opacity=self.config.watermark_opacity
                )
                operations_applied.append("watermarking")
                logger.info("Applied watermarking")
            
            # Calculate quality metrics
            quality_metrics = self.quality_calculator.calculate_metrics(
                original_image, processed_image
            )
            
            processing_time = time.time() - start_time
            
            # Prepare metadata
            result_metadata = {
                "original_size": original_image.size,
                "processed_size": processed_image.size,
                "style": style,
                "raga": raga,
                "config_used": asdict(self.config),
                "input_metadata": metadata or {}
            }
            
            return ProcessingResult(
                processed_image=processed_image,
                original_image=original_image,
                processing_time=processing_time,
                operations_applied=operations_applied,
                quality_metrics=quality_metrics,
                metadata=result_metadata
            )
            
        except Exception as e:
            logger.error(f"Post-processing failed: {e}")
            # Return original image with error info
            return ProcessingResult(
                processed_image=original_image,
                original_image=original_image,
                processing_time=time.time() - start_time,
                operations_applied=["error"],
                quality_metrics={},
                metadata={"error": str(e)}
            )
    
    def process_batch(self, 
                     images: List[Image.Image],
                     styles: List[str] = None,
                     ragas: List[str] = None,
                     show_progress: bool = True) -> List[ProcessingResult]:
        """Process multiple images in batch."""
        results = []
        
        # Prepare style and raga lists
        if styles is None:
            styles = [None] * len(images)
        if ragas is None:
            ragas = [None] * len(images)
        
        # Process images
        iterator = zip(images, styles, ragas)
        if show_progress:
            from tqdm import tqdm
            iterator = tqdm(list(iterator), desc="Post-processing images")
        
        for image, style, raga in iterator:
            result = self.process_image(image, style, raga)
            results.append(result)
        
        return results
    
    def save_result(self, 
                   result: ProcessingResult,
                   output_path: str,
                   save_original: bool = False) -> str:
        """Save processing result to disk."""
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # Save processed image
        result.processed_image.save(
            output_path,
            format=self.config.output_format,
            quality=self.config.output_quality
        )
        
        # Save original if requested
        if save_original:
            original_path = output_path.with_suffix(f"_original{output_path.suffix}")
            result.original_image.save(original_path)
        
        # Save metadata if enabled
        if self.config.preserve_metadata:
            metadata_path = output_path.with_suffix(".json")
            with open(metadata_path, 'w') as f:
                json.dump({
                    "processing_time": result.processing_time,
                    "operations_applied": result.operations_applied,
                    "quality_metrics": result.quality_metrics,
                    "metadata": result.metadata
                }, f, indent=2, default=str)
        
        logger.info(f"Saved processed image to {output_path}")
        return str(output_path)

def create_post_processor(config: Optional[PostProcessingConfig] = None) -> RagamalaPostProcessor:
    """Factory function to create post-processor."""
    if config is None:
        config = PostProcessingConfig()
    
    return RagamalaPostProcessor(config)

def main():
    """Main function for testing post-processing."""
    # Create configuration
    config = PostProcessingConfig(
        enable_super_resolution=False,  # Disable for testing
        enable_cultural_refinement=False  # Disable for testing
    )
    
    # Create post-processor
    processor = create_post_processor(config)
    
    # Create test image
    test_image = Image.new('RGB', (512, 512), color='red')
    
    # Process image
    result = processor.process_image(
        test_image,
        style="rajput",
        raga="bhairav"
    )
    
    print(f"Processing completed in {result.processing_time:.2f}s")
    print(f"Operations applied: {result.operations_applied}")
    print(f"Quality metrics: {result.quality_metrics}")
    
    # Save result
    output_path = "test_output.png"
    saved_path = processor.save_result(result, output_path)
    print(f"Result saved to: {saved_path}")

if __name__ == "__main__":
    main()
